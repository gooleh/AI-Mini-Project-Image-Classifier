# -*- coding: utf-8 -*-
"""AI_MINI_PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IVtakBZDKb6mUwGb6D0w8gbrJ6FaCeyP
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d puneet6060/intel-image-classification

!unzip -q intel-image-classification.zip

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# --- 데이터 준비 ---
train_dir = '/content/seg_train/seg_train/'
validation_dir = '/content/seg_test/seg_test/'

# 이미지 크기 및 에포크 설정
TARGET_SIZE = (100, 100)
EPOCHS = 10

train_datagen = ImageDataGenerator(
    rescale=1./255, rotation_range=30, width_shift_range=0.2,
    height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,
    horizontal_flip=True, fill_mode='nearest')

validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=TARGET_SIZE,
    batch_size=128,
    class_mode='categorical')

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=TARGET_SIZE,
    batch_size=128,
    class_mode='categorical')


# --- 기준 모델 구성 ---
model_baseline = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dropout(0.5),
    Dense(512, activation='relu'),
    Dense(6, activation='softmax')
])

model_baseline.compile(loss='categorical_crossentropy',
                       optimizer=Adam(learning_rate=0.001),
                       metrics=['accuracy'])

print("--- [기준 모델] 학습 시작 ---")
history_baseline = model_baseline.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=EPOCHS,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    verbose=1
)

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# --- 데이터 준비 ---
train_dir = '/content/seg_train/seg_train/'
validation_dir = '/content/seg_test/seg_test/'

# 이미지 크기 및 에포크 설정
TARGET_SIZE = (100, 100)
EPOCHS = 10

train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')
validation_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(train_dir, target_size=TARGET_SIZE, batch_size=128, class_mode='categorical')
validation_generator = validation_datagen.flow_from_directory(validation_dir, target_size=TARGET_SIZE, batch_size=128, class_mode='categorical')


# --- 심층 모델 구성 ---
model_deeper = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    # ★★★ [실험 1] 변경점: 합성곱 층 한 세트 추가 ★★★
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    # ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★

    Flatten(),
    Dropout(0.5),
    Dense(512, activation='relu'),
    Dense(6, activation='softmax')
])

model_deeper.compile(loss='categorical_crossentropy',
                     optimizer=Adam(learning_rate=0.001),
                     metrics=['accuracy'])

print("--- [실험 1: 심층 모델] 학습 시작 ---")
history_deeper = model_deeper.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=EPOCHS,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    verbose=1
)

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# --- 데이터 준비 ---
train_dir = '/content/seg_train/seg_train/'
validation_dir = '/content/seg_test/seg_test/'

# 이미지 크기 및 에포크 설정
TARGET_SIZE = (100, 100)
EPOCHS = 10

train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')
validation_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(train_dir, target_size=TARGET_SIZE, batch_size=128, class_mode='categorical')
validation_generator = validation_datagen.flow_from_directory(validation_dir, target_size=TARGET_SIZE, batch_size=128, class_mode='categorical')


model_lr = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dropout(0.5),
    Dense(512, activation='relu'),
    Dense(6, activation='softmax')
])

# ★★★ [실험 2] 학습률(learning_rate) 조정 ★★★
model_lr.compile(loss='categorical_crossentropy',
                 optimizer=Adam(learning_rate=0.0001), # 학습률 0.001 -> 0.0001
                 metrics=['accuracy'])
# ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★

print("--- [실험 2: 학습률 변경 모델] 학습 시작 ---")
history_lr = model_lr.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=EPOCHS,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    verbose=1
)

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# --- 데이터 준비 ---
train_dir = '/content/seg_train/seg_train/'
validation_dir = '/content/seg_test/seg_test/'

# 이미지 크기 및 에포크 설정
TARGET_SIZE = (100, 100)
EPOCHS = 10

train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')
validation_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(train_dir, target_size=TARGET_SIZE, batch_size=128, class_mode='categorical')
validation_generator = validation_datagen.flow_from_directory(validation_dir, target_size=TARGET_SIZE, batch_size=128, class_mode='categorical')


# --- [실험 3] 드롭아웃 비율 조정 모델 구성 ---
model_dropout = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),

    # ★★★ [실험 3] 드롭아웃(Dropout) 비율 조정 ★★★
    Dropout(0.7), # 드롭아웃 비율 0.5 -> 0.7
    # ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★

    Dense(512, activation='relu'),
    Dense(6, activation='softmax')
])

model_dropout.compile(loss='categorical_crossentropy',
                      optimizer=Adam(learning_rate=0.001),
                      metrics=['accuracy'])

print("--- [실험 3: 드롭아웃 비율 조정 모델] 학습 시작 ---")
history_dropout = model_dropout.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=EPOCHS,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    verbose=1
)

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# --- 데이터 준비 ---
train_dir = '/content/seg_train/seg_train/'
validation_dir = '/content/seg_test/seg_test/'

# 이미지 크기 및 최종 에포크 설정
TARGET_SIZE = (100, 100)
FINAL_EPOCHS = 25

# 데이터 생성기 (Data Augmentation 포함)
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=TARGET_SIZE,
    batch_size=128,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=TARGET_SIZE,
    batch_size=128,
    class_mode='categorical'
)

# --- 최종 모델 구성 ---
# 가장 잠재력이 높았던 Dropout(0.7) 모델 구조
final_model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dropout(0.7), # 규제 강화를 위해 Dropout 비율을 높게 유지
    Dense(512, activation='relu'),
    Dense(6, activation='softmax')
])

# 모델 컴파일
final_model.compile(
    loss='categorical_crossentropy',
    optimizer=Adam(learning_rate=0.001),
    metrics=['accuracy']
)

# 최종 모델 구조 요약 출력
final_model.summary()

print("\n--- 최종 모델 학습 시작 (Epochs: 25) ---")

# 최종 모델 학습 실행
history_final = final_model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=FINAL_EPOCHS,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    verbose=1
)

# 학습 결과 시각화
acc = history_final.history['accuracy']
val_acc = history_final.history['val_accuracy']
loss = history_final.history['loss']
val_loss = history_final.history['val_loss']
epochs_range = range(FINAL_EPOCHS)

plt.figure(figsize=(14, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# 최종 성능 평가
print("\n--- 최종 모델 성능 평가 ---")
final_loss, final_accuracy = final_model.evaluate(validation_generator)
print(f"Final Validation Loss: {final_loss:.4f}")
print(f"Final Validation Accuracy: {final_accuracy:.4f}")